<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Finance | Eugene Zhulenev]]></title>
  <link href="http://eugenezhulenev.com/blog/categories/finance/atom.xml" rel="self"/>
  <link href="http://eugenezhulenev.com/"/>
  <updated>2014-11-19T22:10:30-05:00</updated>
  <id>http://eugenezhulenev.com/</id>
  <author>
    <name><![CDATA[Eugene Zhulenev]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Building Twitter Live Stream Analytics With Spark and Cassandra]]></title>
    <link href="http://eugenezhulenev.com/blog/2014/11/20/twitter-analytics-with-spark/"/>
    <updated>2014-11-20T20:01:15-05:00</updated>
    <id>http://eugenezhulenev.com/blog/2014/11/20/twitter-analytics-with-spark</id>
    <content type="html"><![CDATA[<blockquote>
  <p>This is repost of my article from <a href="http://io.pellucid.com/blog/building-twitter-live-stream-analytics-with-spark-and-cassandra">Pellucid Tech Blog</a></p>
</blockquote>

<h3 id="background">Background</h3>

<p>At <a href="http://pellucid.com">Pellucid Analytics</a> we we are building a platform that
automates and simplifies the creation of data-driven chartbooks, so that it takes
minutes instead of hours to get from raw data to powerful visualizations and compelling stories.</p>

<p>One of industries we are focusing on is Investment Banking. We are helping IB advisory
professionals build pitch-books, and provide them with analytical and quantitative support
to sell their ideas. Comparable Companies Analysis is central to this business.</p>

<blockquote>
  <p>Comparable company analysis starts with establishing a peer group consisting of similar companies of similar size in the same industry and region.</p>
</blockquote>

<p>The problem we are faced with is finding a scalable solution to establish a peer group for any chosen company.</p>

<!-- more -->

<h3 id="approaches-that-we-tried">Approaches That We Tried</h3>

<h4 id="company-industry">Company Industry</h4>

<p>Data vendors provide <a href="http://en.wikipedia.org/wiki/Industry_classification">industry classification</a>
for each company, and it helps a lot in industries like retail (Wal-Mart is good comparable to Costco),
energy (Chevron and Exxon Mobil) but it stumbles with many other companies. People tend to compare
Amazon with Google as a two major players in it business, but data vendors tend to put Amazon in retail industry with Wal-Mart/Costco as comparables.</p>

<h4 id="company-financials-and-valuation-multiples">Company Financials and Valuation Multiples</h4>

<p>We tried cluster analysis and k-nearest neighbors to group companies based on their
financials (Sales, Revenue) and valuation multiples (EV/EBIDTA, P/E). However assumptions
that similar companies will have similar valuations multiples is wrong. People compare
Twitter with Facebook as two biggest companies in social media, but based on their financials
they don’t have too much in common. Facebook 2013 revenue is almost $8 billion and Twitter has only $600 million.</p>

<h3 id="novel-approach">Novel Approach</h3>

<p>We came up with an idea that if companies are often mentioned in news articles and tweets together, it’s probably a sign that people think about them as comparable companies. In this post I’ll show how we built proof of concept for this idea with Spark, Spark Streaming and Cassandra. We use only Twitter live stream data for now, accessing high quality news data is a bit more complicated problem.</p>

<!-- more -->

<p>Let’s take for example this tweet from CNN:</p>

<blockquote class="twitter-tweet" lang="en"><p>Trying to spot the next <a href="https://twitter.com/search?q=%24FB&amp;src=ctag">$FB</a> or <a href="https://twitter.com/search?q=%24TWTR&amp;src=ctag">$TWTR</a>? These 10 startups are worth keeping an eye on <a href="http://t.co/FEKNtm7QqB">http://t.co/FEKNtm7QqB</a></p>&mdash; CNN Public Relations (@CNNPR) <a href="https://twitter.com/CNNPR/status/518083527863435264">October 3, 2014</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>From this tweet we can derive 2 mentions for 2 companies. For Facebook it will be Twitter and vice-versa. If we collect tweets for all companies over some period of time, and take a ratio of joint appearance in same tweet as a measure of “similarity”, we can build comparable company recommendations based on this measure.</p>

<h3 id="data-model">Data Model</h3>

<p>We use <a href="http://cassandra.apache.org/">Cassandra</a> to store all mentions, aggregates and final recommendations.
We use <a href="https://github.com/websudos/phantom">Phantom DSL</a> for scala to define schema
and for most of Cassandra operations (spark integration is not yet supported in Phantom).</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
<span class="comment">/**
 * Mention of focus company
 *
 * @param ticker   ticker of focus company
 * @param source   source of this mention (Twitter, RSS, etc…)
 * @param sourceId source specific id
 * @param time     time
 * @param mentions set of other tickers including focus ticker itself
 */</span>
<span class="keyword">case</span> <span class="type">class</span> <span class="class">Mention</span>(<span class="key">ticker</span>: Ticker, <span class="key">source</span>: <span class="predefined-type">String</span>, <span class="key">sourceId</span>: <span class="predefined-type">String</span>, <span class="key">time</span>: DateTime, <span class="key">mentions</span>: <span class="predefined-type">Set</span>[Ticker])&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;sealed <span class="type">class</span> <span class="class">MentionRecord</span> <span class="directive">extends</span> CassandraTable[MentionRecord, Mention] with <span class="predefined-type">Serializable</span> {&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;override val <span class="key">tableName</span>: <span class="predefined-type">String</span> = <span class="error">“</span>mention<span class="error">”</span>&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;object ticker    <span class="directive">extends</span> StringColumn    (<span class="local-variable">this</span>)  with PartitionKey[<span class="predefined-type">String</span>]
  object source    <span class="directive">extends</span> StringColumn    (<span class="local-variable">this</span>)  with PrimaryKey[<span class="predefined-type">String</span>]
  object time      <span class="directive">extends</span> DateTimeColumn  (<span class="local-variable">this</span>)  with PrimaryKey[DateTime]
  object source_id <span class="directive">extends</span> StringColumn    (<span class="local-variable">this</span>)  with PrimaryKey[<span class="predefined-type">String</span>]
  object mentions  <span class="directive">extends</span> SetColumn[MentionRecord, Mention, <span class="predefined-type">String</span>] (<span class="local-variable">this</span>)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> <span class="function">fromRow</span>(<span class="key">r</span>: Row): Mention = {
    Mention(Ticker(ticker(r)), source(r), source_id(r), time(r), mentions(r) map Ticker)
  }
}
</pre></div>
</div>
 </figure></notextile></div></p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
<span class="comment">/**
 * Count mentions for each ticker pair
 *
 * @param ticker        ticker of focus company
 * @param mentionedWith mentioned with this ticker
 * @param count         number of mentions
 */</span>
<span class="keyword">case</span> <span class="type">class</span> <span class="class">MentionsAggregate</span>(<span class="key">ticker</span>: Ticker, <span class="key">mentionedWith</span>: Ticker, <span class="key">count</span>: <span class="predefined-type">Long</span>)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;sealed <span class="type">class</span> <span class="class">MentionsAggregateRecord</span> <span class="directive">extends</span> CassandraTable[MentionsAggregateRecord, MentionsAggregate] {&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;override val <span class="key">tableName</span>: <span class="predefined-type">String</span> = <span class="error">“</span>mentions_aggregate<span class="error">”</span>&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;object ticker         <span class="directive">extends</span> StringColumn (<span class="local-variable">this</span>) with PartitionKey[<span class="predefined-type">String</span>]
  object mentioned_with <span class="directive">extends</span> StringColumn (<span class="local-variable">this</span>) with PrimaryKey[<span class="predefined-type">String</span>]
  object counter        <span class="directive">extends</span> LongColumn   (<span class="local-variable">this</span>)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> <span class="function">fromRow</span>(<span class="key">r</span>: Row): MentionsAggregate = {
    MentionsAggregate(Ticker(ticker(r)), Ticker(mentioned_with(r)), counter(r))
  }
}
</pre></div>
</div>
 </figure></notextile></div></p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
<span class="comment">/**
 * Recommendation built based on company mentions with other companies
 *
 * @param ticker         focus company ticker
 * @position             recommendation position
 * @param recommendation recommended company ticker
 * @param p              number of times recommended company mentioned together
 *                       with focus company divided by total focus company mentions
 */</span>
<span class="keyword">case</span> <span class="type">class</span> <span class="class">Recommendation</span>(<span class="key">ticker</span>: Ticker, <span class="key">position</span>: <span class="predefined-type">Long</span>, <span class="key">recommendation</span>: Ticker, <span class="key">p</span>: <span class="predefined-type">Double</span>)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;sealed <span class="type">class</span> <span class="class">RecommendationRecord</span> <span class="directive">extends</span> CassandraTable[RecommendationRecord, Recommendation] {&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;override val <span class="key">tableName</span>: <span class="predefined-type">String</span> = <span class="error">“</span>recommendation<span class="error">”</span>&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;object ticker         <span class="directive">extends</span> StringColumn (<span class="local-variable">this</span>) with PartitionKey[<span class="predefined-type">String</span>]
  object position       <span class="directive">extends</span> LongColumn   (<span class="local-variable">this</span>) with PrimaryKey[<span class="predefined-type">Long</span>]
  object recommendation <span class="directive">extends</span> StringColumn (<span class="local-variable">this</span>)
  object p              <span class="directive">extends</span> DoubleColumn (<span class="local-variable">this</span>)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> <span class="function">fromRow</span>(<span class="key">r</span>: Row): Recommendation = {
    Recommendation(Ticker(ticker(r)), position(r), Ticker(recommendation(r)), p(r))
  }
}
</pre></div>
</div>
 </figure></notextile></div></p>

<h3 id="ingest-real-time-twitter-stream">Ingest Real-Time Twitter Stream</h3>

<p>We use <a href="https://spark.apache.org/streaming/">Spark Streaming</a> Twitter integration to subscribe for
real-time twitter updates, then we extract company mentions and put them to Cassandra. Unfortunately Phantom
doesn’t support Spark yet, so we used <a href="https://github.com/datastax/spark-cassandra-connector">Datastax Spark Cassandra Connector</a>
with custom type mappers to map from Phantom-record types into Cassandra tables.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
<span class="type">class</span> <span class="class">MentionStreamFunctions</span>(<span class="annotation">@transient</span> <span class="key">stream</span>: DStream[Mention]) <span class="directive">extends</span> <span class="predefined-type">Serializable</span> {&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">import</span> <span class="include">TickerTypeConverter._</span>&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;TypeConverter.registerConverter(StringToTickerTypeConverter)
  TypeConverter.registerConverter(TickerToStringTypeConverter)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;implicit object MentionMapper <span class="directive">extends</span> DefaultColumnMapper&lt;a href=<span class="string"><span class="delimiter">&quot;</span><span class="content">Map(</span><span class="delimiter">&quot;</span></span> title=<span class="string"><span class="delimiter">&quot;</span><span class="content">ticker&amp;quot;        -&amp;gt; &amp;quot;ticker&amp;quot;,</span></span><span class="error">
</span>    &amp;quot;source&amp;quot;        -&amp;gt; &amp;quot;source&amp;quot;,
    &amp;quot;sourceId&amp;quot;      -&amp;gt; &amp;quot;source_id&amp;quot;,
    &amp;quot;time&amp;quot;          -&amp;gt; &amp;quot;time&amp;quot;,
    &amp;quot;mentions&amp;quot;      -&amp;gt; &amp;quot;mentions<span class="string"><span class="delimiter">&quot;</span><span class="content">&gt;Mention&lt;/a&gt;)&lt;/p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> <span class="function">saveMentionsToCassandra</span>(<span class="key">keyspace</span>: <span class="predefined-type">String</span>) = {
    stream.saveToCassandra(keyspace, MentionRecord.tableName)
  }
}
</pre></div>
</div>
 </figure></notextile></div></p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
  <span class="directive">private</span> val filters = Companies.load().map(c =&amp;gt; s<span class="error">”</span><span class="error">$</span><span class="error">$</span><span class="error">$</span>{c.ticker.value}<span class="error">”</span>)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;val sc = <span class="keyword">new</span> SparkContext(sparkConf)
  val ssc = <span class="keyword">new</span> StreamingContext(sc, Seconds(<span class="integer">2</span>))&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;val stream = TwitterUtils.createStream(ssc, None, filters = filters)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="comment">// Save Twitter Stream to cassandra</span>
  stream.foreachRDD(updates =&amp;gt; log.info(s<span class="error">”</span>Received Twitter stream updates. Count: <span class="error">$</span>{updates.count()}<span class="error">”</span>))
  stream.extractMentions.saveMentionsToCassandra(keySpace)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="comment">// Start Streaming Application</span>
  ssc.start()
</pre></div>
</div>
 </figure></notextile></div></p>

<h3 id="spark-for-aggregation-and-recommendation">Spark For Aggregation and Recommendation</h3>

<p>To come up with comparable company recommendation we use 2-step process.</p>

<h5 id="count-mentions-for-each-pair-of-tickers">1. Count mentions for each pair of tickers</h5>

<p>After <code>Mentions</code> table loaded in Spark as <code>RDD[Mention]</code> we extract pairs of tickers,
and it enables bunch of aggregate and reduce functions from Spark <code>PairRDDFunctions</code>.
With <code>aggregateByKey</code> and given combine functions we efficiently build counter map <code>Map[Ticker, Long]</code> for each
ticker distributed in cluster. From single <code>Map[Ticker, Long]</code> we emit multiple aggregates for each ticket pair.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
<span class="type">class</span> <span class="class">AggregateMentions</span>(<span class="annotation">@transient</span> <span class="key">sc</span>: SparkContext, <span class="key">keyspace</span>: <span class="predefined-type">String</span>)
  <span class="directive">extends</span> CassandraMappers with <span class="predefined-type">Serializable</span> {&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="directive">private</span> type Counter = <span class="predefined-type">Map</span>[Ticker, <span class="predefined-type">Long</span>]&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="directive">private</span> implicit lazy val summ = Semigroup.instance&lt;a href=<span class="string"><span class="delimiter">&quot;</span><span class="content">_ + _</span><span class="delimiter">&quot;</span></span>&gt;<span class="predefined-type">Long</span>&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">a&gt;&lt;</span><span class="delimiter">/</span></span>p&gt;

&lt;p&gt;<span class="directive">private</span> lazy val <span class="key">seqOp</span>: (Counter, Ticker) =&amp;gt; Counter = {
    <span class="keyword">case</span> (counter, ticker) <span class="keyword">if</span> counter.isDefinedAt(ticker) =&amp;gt; counter.updated(ticker, counter(ticker) + <span class="integer">1</span>)
    <span class="keyword">case</span> (counter, ticker) =&amp;gt; counter + (ticker -&amp;gt; <span class="integer">1</span>)
  }&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="directive">private</span> lazy val <span class="key">combOp</span>: (Counter, Counter) =&amp;gt; Counter = {
    <span class="keyword">case</span> (l, r) =&amp;gt; implicitly[Monoid[Counter]].append(l, r)
  }&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> <span class="function">aggregate</span>(): Unit = {
    <span class="comment">// Emit pairs of (Focus Company Ticker, Mentioned With)</span>
    val pairs = sc.cassandraTable&lt;a href=<span class="string"><span class="delimiter">&quot;</span><span class="content">keyspace, MentionRecord.tableName</span><span class="delimiter">&quot;</span></span>&gt;Mention&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">a&gt;.</span></span><span class="error">
</span>      flatMap(mention =&amp;gt; mention.mentions.map((mention.ticker, _)))&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;pre&gt;&lt;code&gt;<span class="comment">// Calculate mentions for each ticker</span>
val aggregated = pairs.aggregateByKey(<span class="predefined-type">Map</span>.empty[Ticker, <span class="predefined-type">Long</span>])(seqOp, combOp)

<span class="comment">// Build MentionsAggregate from counters</span>
val mentionsAggregate = aggregated flatMap {
  <span class="keyword">case</span> (ticker, counter) =&amp;gt; counter map {
    <span class="keyword">case</span> (mentionedWith, count) =&amp;gt; MentionsAggregate(ticker, mentionedWith, count)
  }
}

mentionsAggregate.saveToCassandra(keyspace, MentionsAggregateRecord.tableName)   } } </pre></div>
</div>
 </figure></notextile></div>
</code></pre>

<h5 id="sort-aggregates-and-build-recommendations">2. Sort aggregates and build recommendations</h5>

<p>After aggregates computed, we sort them globally and then group them by key (Ticker). After
all aggregates grouped we produce <code>Recommendation</code> in single traverse distributed for each key.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
<span class="type">class</span> <span class="class">Recommend</span>(<span class="annotation">@transient</span> <span class="key">sc</span>: SparkContext, <span class="key">keyspace</span>: <span class="predefined-type">String</span>)
  <span class="directive">extends</span> CassandraMappers with <span class="predefined-type">Serializable</span> {&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="directive">private</span> <span class="keyword">def</span> <span class="key">toRecommendation</span>: (MentionsAggregate, Int) =&amp;gt; Recommendation = {
    var <span class="key">totalMentions</span>: <span class="predefined-type">Option</span>[<span class="predefined-type">Long</span>] = None&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;pre&gt;&lt;code&gt;{
  <span class="keyword">case</span> (aggregate, idx) <span class="keyword">if</span> totalMentions.isEmpty =&amp;gt;
    totalMentions = Some(aggregate.count)
    Recommendation(aggregate.ticker, idx, aggregate.mentionedWith, <span class="integer">1</span>)

  <span class="keyword">case</span> (aggregate, idx) =&amp;gt;
    Recommendation(aggregate.ticker, idx,
                   aggregate.mentionedWith,
                   aggregate.count.toDouble / totalMentions.get)
}   }
&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">code&gt;&lt;</span><span class="delimiter">/</span></span>pre&gt;

&lt;p&gt;<span class="keyword">def</span> <span class="function">recommend</span>(): Unit = {
    val aggregates = sc.
               cassandraTable&lt;a href=<span class="string"><span class="delimiter">&quot;</span><span class="content">keyspace, MentionsAggregateRecord.tableName</span><span class="delimiter">&quot;</span></span>&gt;MentionsAggregate&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">a&gt;.</span></span><span class="error">
</span>               sortBy(_.count, ascending = <span class="predefined-constant">false</span>)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;pre&gt;&lt;code&gt;val recommendations = aggregates.
  groupBy(_.ticker).
  mapValues(_.zipWithIndex).
  flatMapValues(_ map toRecommendation.tupled).values

recommendations.saveToCassandra(keyspace, RecommendationRecord.tableName)   } } </pre></div>
</div>
 </figure></notextile></div>
</code></pre>

<h3 id="results">Results</h3>

<p>You can check comparable company recommendations build from Twitter stream using <a href="http://pellucidanalytics.github.io/tweet-driven-comparable-companies/comparables/comps.html">this link</a>.</p>

<p>Cassandra and Spark works perfectly together and allows you to build scalable data-driven applications, that are super easy to scale out and handle gigabytes and terabytes of data. In this particular case, it’s probably an overkill. Twitter doesn’t have enough finance-related activity to produce serious load. However it’s easy to extend this application and add other streams: Bloomberg News Feed, Thompson Reuters, etc.</p>

<blockquote>
  <p>The code for this application app can be found on <a href="https://github.com/ezhulenev/tweet-driven-comparable-companies">Github</a></p>
</blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Stock Price Prediction With Big Data and Machine Learning]]></title>
    <link href="http://eugenezhulenev.com/blog/2014/11/14/stock-price-prediction-with-big-data-and-machine-learning/"/>
    <updated>2014-11-14T21:03:35-05:00</updated>
    <id>http://eugenezhulenev.com/blog/2014/11/14/stock-price-prediction-with-big-data-and-machine-learning</id>
    <content type="html"><![CDATA[<p>Apache Spark and Spark MLLib for building price movement prediction model from order log data.</p>

<blockquote>
  <p>The code for this application app can be found on <a href="https://github.com/ezhulenev/orderbook-dynamics">Github</a></p>
</blockquote>

<h3 id="synopsis">Synopsis</h3>

<p>This post is based on <a href="https://raw.github.com/ezhulenev/scala-openbook/master/assets/Modeling-high-frequency-limit-order-book-dynamics-with-support-vector-machines.pdf">Modeling high-frequency limit order book dynamics with support vector machines</a> paper.
Roughly speaking I’m implementing ideas introduced in this paper in scala with <a href="https://spark.apache.org/">Spark</a> and <a href="https://spark.apache.org/mllib/">Spark MLLib</a>.
Authors are using sampling, I’m going to use full order log from <a href="http://www.nyxdata.com/Data-Products/NYSE-OpenBook-History">NYSE</a> (sample data is available from <a href="ftp://ftp.nyxdata.com/Historical%20Data%20Samples/TAQ%20NYSE%20OpenBook/">NYSE FTP</a>), just because
I can easily do it with Spark. Instead of using SVM, I’m going to use <a href="http://spark.apache.org/docs/latest/mllib-decision-tree.html">Decision Tree</a> algorithm for classification,
because in Spark MLLib it supports multiclass classification out of the box.</p>

<p>If you want to get deep understanding of the problem and proposed solution, you need to read the paper.
I’m going to give high level overview of the problem in less academic language, in one or two paragraphs.</p>

<blockquote>
  <p>Predictive modelling is the process by which a model is created or chosen to try to best predict the probability of an outcome.</p>
</blockquote>

<!-- more -->

<h4 id="model-architecture">Model Architecture</h4>

<p>Authors are proposing framework for extracting feature vectors from from raw order log data, that can be used as input to
machine learning classification method (SVM or Decision Tree for example) to predict price movement (Up, Down, Stationary). Given a set of training data
with assigned labels (price movement) classification algorithm builds a model that assigns new examples into one of pre-defined categories.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
Time(sec)            Price($)   Volume      Event Type      Direction
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
34203.011926972      598.68     10          submission      ask
34203.011926973      594.47     15          submission      bid
34203.011926974      594.49     20          submission      bid
34203.011926981      597.68     30          submission      ask
34203.011926991      594.47     15          execution       ask
34203.011927072      597.68     10          cancellation    ask
34203.011927082      599.88     12          submission      ask
34203.011927097      598.38     11          submission      ask
</pre></div>
</div>
 </figure></notextile></div></p>

<p>In the table, each row of the message book represents a trading event that could be either a order submission,
order cancellation, or order execution. The arrival time measured from midnight,
is in seconds and nanoseconds; price is in US dollars, and the Volume is in number of shares.
Ask - I’m selling and asking for this price, Bid - I want to buy for this price.</p>

<p>From this log it’s very easy to reconstruct state of order book after each entry. You can read more about <a href="http://www.investopedia.com/terms/o/order-book.asp">order book</a>
and <a href="http://www.investopedia.com/university/intro-to-order-types/limit-orders.asp">limit order book</a> in Investopedia,
I’m not going to dive into details. Concepts are super easy for understanding.</p>

<blockquote>
  <p>An electronic list of buy and sell orders for a specific security or financial instrument, organized by price level.</p>
</blockquote>

<h4 id="feature-extraction-and-training-data-preparation">Feature Extraction and Training Data Preparation</h4>

<p>After order books are reconstructed from order log, we can derive attributes, that will form feature vectors used as input to <code>classification model</code>.</p>

<p>Attributes are divided into three categories: basic, time-insensitive, and time-sensitive, all of which can be directly computed from the data.
Attributes in the basic set are the prices and volumes at both ask and bid sides up to n = 10 different levels (that is, price levels in the order book at a given moment),
which can be directly fetched from the order book. Attributes in the time-insensitive set are easily computed from the basic set at a single point in time.
Of this, bid-ask spread and mid-price, price ranges, as well as average price and volume at different price levels are calculated in feature sets <code>v2</code>, <code>v3</code>, and <code>v5</code>, respectively;
while <code>v5</code> is designed to track the accumulated differences of price and volume between ask and bid sides. By further taking the recent history of current data into consideration,
we devise the features in the time-sensitive set. More about calculating other attributes can be found in <a href="https://raw.github.com/ezhulenev/scala-openbook/master/assets/Modeling-high-frequency-limit-order-book-dynamics-with-support-vector-machines.pdf">original paper</a>.</p>

<p><img class="center" src="https://raw.github.com/ezhulenev/scala-openbook/master/assets/features.png"></p>

<h4 id="labeling-training-data">Labeling Training Data</h4>

<p>To prepare training data for machine learning it’s also required to label each point with price movement observed over some time horizon (1 second fo example).
It’s straightforward task that only requires two order books: current order book and order book after some period of time.</p>

<p>I’m going to use <code>MeanPriceMove</code> label that can be: <code>Stationary</code>, <code>Up</code> or <code>Down</code>.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;trait <span class="predefined-type">Label</span>[L] <span class="directive">extends</span> <span class="predefined-type">Serializable</span> { label =&amp;gt;
  <span class="keyword">def</span> <span class="function">apply</span>(<span class="key">current</span>: OrderBook, <span class="key">future</span>: OrderBook): <span class="predefined-type">Option</span>[L]
}&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;sealed trait MeanPriceMove&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;object MeanPriceMove {
  <span class="keyword">case</span> object Up <span class="directive">extends</span> MeanPriceMove
  <span class="keyword">case</span> object Down <span class="directive">extends</span> MeanPriceMove
  <span class="keyword">case</span> object Stationary <span class="directive">extends</span> MeanPriceMove
}&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;object MeanPriceMovementLabel <span class="directive">extends</span> <span class="predefined-type">Label</span>[MeanPriceMove] {&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="directive">private</span>[<span class="local-variable">this</span>] val basicSet = BasicSet.apply(BasicSet.Config.default)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> <span class="function">apply</span>(<span class="key">current</span>: OrderBook, <span class="key">future</span>: OrderBook): <span class="predefined-type">Option</span>[MeanPriceMove] = {
    val currentMeanPrice = basicSet.meanPrice(current)
    val futureMeanPrice = basicSet.meanPrice(future)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;pre&gt;&lt;code&gt;val <span class="key">cell</span>: Cell[MeanPriceMove] =
   currentMeanPrice.zipMap(futureMeanPrice) {
    (currentMeanValue, futureMeanValue) =&amp;gt;
      <span class="keyword">if</span> (currentMeanValue == futureMeanValue)
        MeanPriceMove.Stationary
      <span class="keyword">else</span> <span class="keyword">if</span> (currentMeanValue &amp;gt; futureMeanValue)
        MeanPriceMove.Down
      <span class="keyword">else</span>
        MeanPriceMove.Up
    }

cell.toOption   } } </pre></div>
</div>
 </figure></notextile></div>
</code></pre>

<h3 id="order-log-data">Order Log Data</h3>

<p>I’m going to use <a href="http://www.nyxdata.com/Data-Products/NYSE-OpenBook-History">NYSE TAQ OpenBook</a> orders data, and parse it with <a href="https://github.com/ezhulenev/scala-openbook">Scala OpenBook</a>
library. It’s easiest data set to get, free sample data for 2 trading days is available for download at <a href="ftp://ftp.nyxdata.com/Historical%20Data%20Samples/TAQ%20NYSE%20OpenBook/">NYSE FTP</a>.</p>

<blockquote>
  <p>TAQ (Trades and Quotes) historical data products provide a varying range of market depth on a T+1 basis for covered markets.
TAQ data products are used to develop and backtest trading strategies, analyze market trends as seen in a real-time ticker plant environment, and research markets for regulatory or audit activity.</p>
</blockquote>

<h3 id="prepare-training-data">Prepare Training Data</h3>

<p><code>OrderBook</code> is two sorted maps, where key is price and value is volume.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
<span class="keyword">case</span> <span class="type">class</span> <span class="class">OrderBook</span>(<span class="key">symbol</span>: <span class="predefined-type">String</span>,
                     <span class="key">buy</span>: <span class="predefined-type">TreeMap</span>[Int, Int] = <span class="predefined-type">TreeMap</span>.empty,
                     <span class="key">sell</span>: <span class="predefined-type">TreeMap</span>[Int, Int] = <span class="predefined-type">TreeMap</span>.empty)
</pre></div>
</div>
 </figure></notextile></div></p>

<h4 id="feature-sets">Feature Sets</h4>

<p>I’m using <code>Cell</code> from <a href="https://github.com/pellucidanalytics/framian">Framian</a> library to represent extracted feature values. It can be <code>Value</code>, <code>NA</code> or <code>NM</code>.</p>

<p>As defined in original paper we have three feature sets, first two calculated from <code>OrderBook</code>, last one requires <code>OrdersTrail</code> which effectively is
window computation over raw order log.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
sealed trait <span class="predefined-type">BasicAttribute</span>[T] <span class="directive">extends</span> <span class="predefined-type">Serializable</span> { self =&amp;gt;
  <span class="keyword">def</span> <span class="function">apply</span>(<span class="key">orderBook</span>: OrderBook): Cell[T]&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> map&lt;a href=<span class="string"><span class="delimiter">&quot;</span><span class="content">f: T =&amp;gt; T2</span><span class="delimiter">&quot;</span></span>&gt;T2&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">a&gt;: BasicAttribute[T2] = new BasicAttribute[T2] {</span></span><span class="error">
</span>    <span class="keyword">def</span> <span class="function">apply</span>(<span class="key">orderBook</span>: OrderBook): Cell[T2] = self(orderBook).map(f)
  }
}
</pre></div>
</div>
 </figure></notextile></div></p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
sealed trait TimeInsensitiveAttribute[T] <span class="directive">extends</span> <span class="predefined-type">Serializable</span> { self =&amp;gt;
  <span class="keyword">def</span> <span class="function">apply</span>(<span class="key">orderBook</span>: OrderBook): Cell[T]&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> map&lt;a href=<span class="string"><span class="delimiter">&quot;</span><span class="content">f: T =&amp;gt; T2</span><span class="delimiter">&quot;</span></span>&gt;T2&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">a&gt;: TimeInsensitiveAttribute[T2] = new TimeInsensitiveAttribute[T2] {</span></span><span class="error">
</span>    <span class="keyword">def</span> <span class="function">apply</span>(<span class="key">orderBook</span>: OrderBook): Cell[T2] = self(orderBook).map(f)
  }
}
</pre></div>
</div>
 </figure></notextile></div></p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
trait TimeSensitiveAttribute[T] <span class="directive">extends</span> <span class="predefined-type">Serializable</span> { self =&amp;gt;
  <span class="keyword">def</span> <span class="function">apply</span>(<span class="key">ordersTrail</span>: <span class="predefined-type">Vector</span>[OpenBookMsg]): Cell[T]&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> map&lt;a href=<span class="string"><span class="delimiter">&quot;</span><span class="content">f: T =&amp;gt; T2</span><span class="delimiter">&quot;</span></span>&gt;T2&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">a&gt;: TimeSensitiveAttribute[T2] = new TimeSensitiveAttribute[T2] {</span></span><span class="error">
</span>    <span class="keyword">def</span> <span class="function">apply</span>(<span class="key">ordersTrail</span>: <span class="predefined-type">Vector</span>[OpenBookMsg]): Cell[T2] = self(ordersTrail).map(f)
  }
}
</pre></div>
</div>
 </figure></notextile></div></p>

<p>and it’s how features calculation looks like</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
<span class="type">class</span> <span class="class">BasicSet</span> <span class="directive">private</span>[attribute] (val <span class="key">config</span>: BasicSet.Config) <span class="directive">extends</span> <span class="predefined-type">Serializable</span> {
  <span class="directive">private</span>[attribute] <span class="keyword">def</span> <span class="function">askPrice</span>(<span class="key">orderBook</span>: OrderBook)(<span class="key">i</span>: Int): Cell[Int] = {
    Cell.fromOption {
      orderBook.sell.keySet.drop(i - <span class="integer">1</span>).headOption
    }
  }&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="directive">private</span>[attribute] <span class="keyword">def</span> <span class="function">bidPrice</span>(<span class="key">orderBook</span>: OrderBook)(<span class="key">i</span>: Int): Cell[Int] = {
    Cell.fromOption {
      val bidPrices = orderBook.buy.keySet
      <span class="keyword">if</span> (bidPrices.size &amp;gt;= i) {
        bidPrices.drop(bidPrices.size - i).headOption
      } <span class="keyword">else</span> None
    }
  }&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="directive">private</span> <span class="keyword">def</span> attribute&lt;a href=<span class="string"><span class="delimiter">&quot;</span><span class="content">f: OrderBook =&amp;gt; Cell[T]</span><span class="delimiter">&quot;</span></span>&gt;T&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">a&gt;: BasicAttribute[T] = new BasicAttribute[T] {</span></span><span class="error">
</span>    <span class="keyword">def</span> <span class="function">apply</span>(<span class="key">orderBook</span>: OrderBook): Cell[T] = f(orderBook)
  }&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> <span class="function">askPrice</span>(<span class="key">i</span>: Int): <span class="predefined-type">BasicAttribute</span>[Int] = attribute(askPrice(_)(i))&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> <span class="function">bidPrice</span>(<span class="key">i</span>: Int): <span class="predefined-type">BasicAttribute</span>[Int] = attribute(bidPrice(_)(i))&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;val <span class="key">meanPrice</span>: <span class="predefined-type">BasicAttribute</span>[<span class="predefined-type">Double</span>] = {
    val ask1 = askPrice(<span class="integer">1</span>)
    val bid1 = bidPrice(<span class="integer">1</span>)
    <span class="predefined-type">BasicAttribute</span>.from(orderBook =&amp;gt;
      ask1(orderBook).zipMap(bid1(orderBook)) {
        (ask, bid) =&amp;gt; (ask.toDouble + bid.toDouble) / <span class="integer">2</span>
      })
  }
}
</pre></div>
</div>
 </figure></notextile></div></p>

<h4 id="label-training-data">Label Training Data</h4>

<p>To extract labeled data from orders I’m using <code>LabeledPointsExtractor</code></p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
<span class="type">class</span> <span class="class">LabeledPointsExtractor</span>[<span class="key">L</span>: LabelEncode] {&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">def</span> <span class="function">labeledPoints</span>(<span class="key">orders</span>: <span class="predefined-type">Vector</span>[OpenBookMsg]): <span class="predefined-type">Vector</span>[LabeledPoint] = {
    log.debug(s<span class="error">”</span>Extract labeled points from orders log. Log <span class="key">size</span>: <span class="error">$</span>{orders.size}<span class="error">”</span>)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;pre&gt;&lt;code&gt;<span class="comment">// ...   } } </span></pre></div>
</div>
 </figure></notextile></div>
</code></pre>

<p>and it can be constructed nicely with builder</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
val extractor = {
    <span class="keyword">import</span> <span class="include">com.scalafi.dynamics.attribute.LabeledPointsExtractor._</span>
    (LabeledPointsExtractor.newBuilder()
      += basic(&lt;em&gt;.askPrice(<span class="integer">1</span>))
      += basic(&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">em&gt;.bidPrice(1))</span></span><span class="error">
</span>      += basic(_.meanPrice)
      ).result(symbol, MeanPriceMovementLabel, LabeledPointsExtractor.Config(<span class="integer">1</span>.millisecond))
  }
</pre></div>
</div>
 </figure></notextile></div></p>

<p>This <code>extractor</code> will prepare labeled points using <code>MeanPriceMovementLabel</code> with 3 features: ask price, bid price and mean price</p>

<h3 id="run-classification-model">Run Classification Model</h3>

<p>In “real” application I’m using 36 features from all 3 feature sets. I run my tests with sample data from NYSE ftp,
<code>EQY_US_NYSE_BOOK_20130403</code> for model training and <code>EQY_US_NYSE_BOOK_20130404</code> for model validation.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
object DecisionTreeDynamics <span class="directive">extends</span> App with ConfiguredSparkContext with FeaturesExtractor {
  <span class="directive">private</span> val log = LoggerFactory.getLogger(<span class="local-variable">this</span>.getClass)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;<span class="keyword">case</span> <span class="type">class</span> <span class="class">Config</span>(<span class="key">training</span>: <span class="predefined-type">String</span> = <span class="error">“</span><span class="error">”</span>,
                    <span class="key">validation</span>: <span class="predefined-type">String</span> = <span class="error">“</span><span class="error">”</span>,
                    <span class="key">filter</span>: <span class="predefined-type">Option</span>[<span class="predefined-type">String</span>] = None,
                    <span class="key">symbol</span>: <span class="predefined-type">Option</span>[<span class="predefined-type">String</span>] = None)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;val parser = <span class="keyword">new</span> OptionParser&lt;a href=<span class="string"><span class="delimiter">&quot;</span><span class="content">&amp;quot;Order Book Dynamics&amp;quot;</span><span class="delimiter">&quot;</span></span>&gt;Config&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">a&gt; {</span></span><span class="error">
</span>    <span class="comment">// ….</span>
  }&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;p&gt;parser.parse(args, Config()) map { implicit config =&amp;gt;
    val trainingFiles = openBookFiles(<span class="error">“</span>Training<span class="error">”</span>, config.training, config.filter)
    val validationFiles = openBookFiles(<span class="error">“</span>Validation<span class="error">”</span>, config.validation, config.filter)&lt;<span class="regexp"><span class="delimiter">/</span><span class="content">p&gt;</span></span><span class="error">
</span>
&lt;pre&gt;&lt;code&gt;val trainingOrderLog = orderLog(trainingFiles)
log.info(s<span class="string"><span class="delimiter">&quot;</span><span class="content">Training order log size: </span><span class="inline"><span class="inline-delimiter">${</span>trainingOrderLog.count()<span class="inline-delimiter">}</span></span><span class="delimiter">&quot;</span></span>)

<span class="comment">// Configure DecisionTree model</span>
val labelEncode = implicitly[LabelEncode[MeanPriceMove]]
val numClasses = labelEncode.numClasses
val categoricalFeaturesInfo = <span class="predefined-type">Map</span>.empty[Int, Int]
val impurity = <span class="string"><span class="delimiter">&quot;</span><span class="content">gini</span><span class="delimiter">&quot;</span></span>
val maxDepth = <span class="integer">5</span>
val maxBins = <span class="integer">100</span>

val trainingData = trainingOrderLog.extractLabeledData(featuresExtractor(<span class="key">_</span>: <span class="predefined-type">String</span>))
val trainedModels = (trainingData map { <span class="keyword">case</span> LabeledOrderLog(symbol, labeledPoints) =&amp;gt;
  log.info(s<span class="string"><span class="delimiter">&quot;</span><span class="inline"><span class="inline-delimiter">$</span>symbol</span><span class="content">: Train Decision Tree model. Training data size: </span><span class="inline"><span class="inline-delimiter">${</span>labeledPoints.count()<span class="inline-delimiter">}</span></span><span class="delimiter">&quot;</span></span>)
  val model = DecisionTree.trainClassifier(labeledPoints, numClasses, categoricalFeaturesInfo, impurity, maxDepth, maxBins)
  val labelCounts = labeledPoints.map(_.label).countByValue().map {
    <span class="keyword">case</span> (key, count) =&amp;gt; (labelEncode.decode(key.toInt), count)
  }
  log.info(s<span class="string"><span class="delimiter">&quot;</span><span class="inline"><span class="inline-delimiter">$</span>symbol</span><span class="content">: Label counts: [</span><span class="inline"><span class="inline-delimiter">${</span>labelCounts.mkString(<span class="string"><span class="delimiter">&quot;</span><span class="content">, </span><span class="delimiter">&quot;</span></span>)<span class="inline-delimiter">}</span></span><span class="content">]</span><span class="delimiter">&quot;</span></span>)
  symbol -&amp;gt; model
}).toMap

val validationOrderLog = orderLog(validationFiles)
log.info(s<span class="string"><span class="delimiter">&quot;</span><span class="content">Validation order log size: </span><span class="inline"><span class="inline-delimiter">${</span>validationOrderLog.count()<span class="inline-delimiter">}</span></span><span class="delimiter">&quot;</span></span>)
val validationData = validationOrderLog.extractLabeledData(featuresExtractor(<span class="key">_</span>: <span class="predefined-type">String</span>))

<span class="comment">// Evaluate model on validation data and compute training error</span>
validationData.map { <span class="keyword">case</span> LabeledOrderLog(symbol, labeledPoints) =&amp;gt;

  val model = trainedModels(symbol)

  log.info(s<span class="string"><span class="delimiter">&quot;</span><span class="inline"><span class="inline-delimiter">$</span>symbol</span><span class="content">: Evaluate model on validation data. Validation data size: </span><span class="inline"><span class="inline-delimiter">${</span>labeledPoints.count()<span class="inline-delimiter">}</span></span><span class="delimiter">&quot;</span></span>)
  log.info(s<span class="string"><span class="delimiter">&quot;</span><span class="inline"><span class="inline-delimiter">$</span>symbol</span><span class="content">: Learned classification tree model: </span><span class="inline"><span class="inline-delimiter">$</span>model</span><span class="delimiter">&quot;</span></span>)

  val labelAndPrediction = labeledPoints.map { point =&amp;gt;
    val prediction = model.predict(point.features)
    (point.label, prediction)
  }
  val trainingError = labelAndPrediction.filter(r =&amp;gt; r._1 != r._2).count().toDouble / labeledPoints.count
  log.info(s<span class="string"><span class="delimiter">&quot;</span><span class="inline"><span class="inline-delimiter">$</span>symbol</span><span class="content">: Training Error = </span><span class="delimiter">&quot;</span></span> + trainingError)
}   } } </pre></div>
</div>
 </figure></notextile></div>
</code></pre>

<h4 id="training-error">Training Error</h4>

<p>Output of running Decision Tree classification for single symbol <code>ORCL</code>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="CodeRay">
  <div class="code"><pre>
ORCL: Train Decision Tree model. Training data size: 64064
ORCL: Trained model in 3740 millis
ORCL: Label counts: [Stationary -&amp;gt; 42137, Down -&amp;gt; 10714, Up -&amp;gt; 11213]
ORCL: Evaluate model on validation data. Validation data size: 54749
ORCL: Training Error = 0.28603262160039455
</pre></div>
</div>
 </figure></notextile></div></p>

<p>As you can see this pretty simple model was able to successfully classify ~70% of the data.</p>

<h3 id="results">Results</h3>

<p>I was able to relatively easy reproduce fairly complicated research project at much lager scale than in original paper.</p>

<p>Latest Big Data technologies allows to build models using all available data, and stop doing samplings.
Using all of the data helps to build best possible models and capture all details from full data set.</p>

<blockquote>
  <p>The code for this application app can be found on <a href="https://github.com/ezhulenev/orderbook-dynamics">Github</a></p>
</blockquote>
]]></content>
  </entry>
  
</feed>
