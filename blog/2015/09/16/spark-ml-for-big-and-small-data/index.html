
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Optimizing Spark Machine Learning for Small Data - Eugene Zhulenev</title>
  <meta name="author" content="Eugene Zhulenev">

  
  <meta name="description" content="Update 2015-10-08: Optimization “hack” described in this post still works, however we don’t use it in production anymore. With careful parallelism &hellip;">
  <meta name="keywords" content="spark, scala, dataframe, machine learning">

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://eugenezhulenev.com/blog/2015/09/16/spark-ml-for-big-and-small-data">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Eugene Zhulenev" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href='https://fonts.googleapis.com/css?family=Noto+Serif:400,700' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-49585535-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>

  <script>
    $(document).ready(function(){
      $('a#github').attr('target','_blank');
      $('a#github').on('click', function() {
         _gaq.push(['_trackEvent', 'ContactMe', 'Click', 'Github']);
      });

      $('a#linkedin').attr('target','_blank');
      $('a#linkedin').on('click', function() {
         _gaq.push(['_trackEvent', 'ContactMe', 'Click', 'LinkedIn']);
       });

      $('a#twitter').attr('target','_blank');
      $('a#twitter').on('click', function() {
         _gaq.push(['_trackEvent', 'ContactMe', 'Click', 'Twitter']);
      });
     });
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Eugene Zhulenev</a></h1>
  
    <h2>Engineering Machine Learning and Audience Modeling at <a href="http://collective.com">Collective</a></h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  
  
</ul>

<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/atom.xml">RSS</a></li>
  <li><a id="github" href="http://github.com/ezhulenev">Github</a></li>
  <li><a id="twitter" href="http://twitter.com/ezhulenev">Twitter</a></li>
  <li><a id="linkedin" href="http://linkedin.com/in/eugenezhulenev">Linkedin</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Optimizing Spark Machine Learning for Small Data</h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-09-16T10:04:25-04:00" pubdate data-updated="true">Sep 16<span>th</span>, 2015</time>
        
           | <a href="#disqus_thread"
             data-disqus-identifier="http://eugenezhulenev.com">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><blockquote>
  <p><strong>Update 2015-10-08</strong>: Optimization “hack” described in this post still works, however we don’t use it in production anymore. 
With careful parallelism config, overhead introduced by distributed models is negligible.</p>
</blockquote>

<p>You’ve all probably already know how awesome is Spark for doing Machine Learning on Big Data. However I’m pretty sure
no one told you how bad (slow) it can be on Small Data. </p>

<p>As I mentioned in my <a href="/blog/2015/09/09/audience-modeling-with-spark-ml-pipelines">previous post</a>, we
extensively use Spark for doing machine learning and audience modeling. It turned out that in some cases, for example when
we are starting optimization for new client/campaign we simply don’t have enough positive examples to construct big enough dataset, so that
using Spark would make sense.</p>

<!-- more -->

<h3 id="spark-ml-from-10000-feet">Spark ML from 10000 feet</h3>

<p>Essentially every machine learning algorithm is a function minimization, where function value depends on some calculation using data in <code>RDD</code>.
For example logistic regression can calculate function value 1000 times before it will converge and find optimal parameters. It means that it will 
compute some <code>RDD</code> 1000 times. In case of <code>LogisticRegression</code> it’s doing <code>RDD.treeAggregate</code> which is supper efficient, but still it’s distributed 
computation.</p>

<p>Now imagine that all the data you have is 50000 rows, and you have for example 1000 partitions. It means that each partition has only 50 rows. And 
each <code>RDD.treeAggregate</code> on every iteration serializing closures, sending them to partitions and collecting result back. 
It’s <strong>HUGE OVERHEAD</strong> and huge load on a driver.</p>

<h3 id="throw-away-spark-and-use-pythonr">Throw Away Spark and use Python/R?</h3>

<p>It’s definitely an option, but we don’t want to build multiple systems for data of different size. Spark ML pipelines are awesome abstraction,
and we want to use it for all machine learning jobs. Also we want to use the same algorithm, so results would be consistent if dataset size
just crossed the boundary between small and big data.</p>

<h3 id="run-logisticregression-in-local-mode">Run LogisticRegression in ‘Local Mode’</h3>

<p>What if Spark could run the same machine learning algorithm, but instead of using <code>RDD</code> for storing input data, it would use <code>Arrays</code>?
It solves all the problems, you get consistent model, computed 10-20x faster because it doesn’t need distributed computations.</p>

<p>That’s exactly approach I used in <a href="https://github.com/collectivemedia/spark-ext">Spark Ext</a>, it’s called <a href="https://github.com/collectivemedia/spark-ext/blob/master/sparkext-mllib/src/main/scala/org/apache/spark/ml/classification/LocalLogisticRegression.scala">LocalLogisticRegression</a>.
It’s mostly copy-pasta from Spark <code>LogisticRegression</code>, but when input data frame has only single partition, it’s running
function optimization on one of the executors using <code>mapPartition</code> function, essentially using Spark as distributed executor service.</p>

<p>This approach is much better than collecting data to driver, because you are not limited by driver computational resources.</p>

<p>When <code>DataFrame</code> has more than 1 partition it just falls back to default distributed logistic regression.</p>

<p>Code for new <code>train</code> method looks like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="CodeRay">
  <div class="code"><pre>
<span class="keyword">def</span> <span class="function">trainLocal</span>(
      <span class="key">instances</span>: <span class="predefined-type">Array</span>[(<span class="predefined-type">Double</span>, <span class="predefined-type">Vector</span>)]
    ): (LogisticRegressionModel, <span class="predefined-type">Array</span>[<span class="predefined-type">Double</span>]) = ...

def train(<span class="key">dataset</span>: DataFrame): LogisticRegressionModel = {

  <span class="keyword">if</span> (dataset.rdd.partitions.length == <span class="integer">1</span>) {
    log.info(s<span class="string"><span class="delimiter">&quot;</span><span class="content">Build LogisticRegression in local mode</span><span class="delimiter">&quot;</span></span>)

    val (model, objectiveHistory) = extractLabeledPoints(dataset).map {
      <span class="keyword">case</span> LabeledPoint(<span class="key">label</span>: <span class="predefined-type">Double</span>, <span class="key">features</span>: <span class="predefined-type">Vector</span>) =&gt; (label, features)
    }.mapPartitions { instances =&gt;
      Seq(trainLocal(instances.toArray)).toIterator
    }.first()

    val logRegSummary = <span class="keyword">new</span> BinaryLogisticRegressionTrainingSummary(
      model.transform(dataset),
      probabilityCol,
      labelCol,
      objectiveHistory)
    model.setSummary(logRegSummary)

  } <span class="keyword">else</span> {
    log.info(s<span class="string"><span class="delimiter">&quot;</span><span class="content">Fallback to distributed LogisticRegression</span><span class="delimiter">&quot;</span></span>)

    val that = classOf[LogisticRegression].getConstructor(classOf[<span class="predefined-type">String</span>]).newInstance(uid)
    val logisticRegression = copyValues(that)
    <span class="comment">// Scala Reflection magic to call protected train method</span>
    ...
    logisticRegression.train(dataset)
  }
}      
</pre></div>
</div>
 </figure></notextile></div>

<p>If input dataset size is less than 100000 rows, it will be placed inside single partition, and regression model will be trained in local mode.</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="CodeRay">
  <div class="code"><pre>
val <span class="key">base</span>: DataFrame = ...
val datasetPartitionSize = <span class="integer">100000</span>

<span class="comment">// Compute optimal partitions size based on base join</span>
val baseSize = base.count()
val numPartitions = (baseSize.toDouble / datasetPartitionSize).ceil.toInt
log.debug(s<span class="string"><span class="delimiter">&quot;</span><span class="content">Response base size: </span><span class="inline"><span class="inline-delimiter">$</span>baseSize</span><span class="delimiter">&quot;</span></span>)
log.debug(s<span class="string"><span class="delimiter">&quot;</span><span class="content">Repartition dataset using </span><span class="inline"><span class="inline-delimiter">$</span>numPartitions</span><span class="content"> partitions</span><span class="delimiter">&quot;</span></span>)
</pre></div>
</div>
 </figure></notextile></div>

<h2 id="results">Results</h2>

<p>With a little ingenuity (and copy paste) Spark became perfect tool for machine learning both on Small and Big Data. Most awesome thing is that this
new <code>LocalLogisticRegression</code> can be used as drop in replacement in Spark ML pipelines, producing exactly the same <code>LogisticRegressionModel</code> at the end.</p>

<p>It might be interesting idea to use this approach in Spark itself, because in this case it would be possible to do it
without doing so many code duplication. I’d love to see if anyone else had the same problem, and how solved it.</p>

<blockquote>
  <p>More cool Spark things in <a href="https://github.com/collectivemedia/spark-ext/">Github</a>.</p>
</blockquote>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Eugene Zhulenev</span></span>

      








  


<time datetime="2015-09-16T10:04:25-04:00" pubdate data-updated="true">Sep 16<span>th</span>, 2015</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/dataframe/'>dataframe</a>, <a class='category' href='/blog/categories/machine-learning/'>machine learning</a>, <a class='category' href='/blog/categories/scala/'>scala</a>, <a class='category' href='/blog/categories/spark/'>spark</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://eugenezhulenev.com/blog/2015/09/16/spark-ml-for-big-and-small-data/" data-via="ezhulenev" data-counturl="http://eugenezhulenev.com/blog/2015/09/16/spark-ml-for-big-and-small-data/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2015/09/09/audience-modeling-with-spark-ml-pipelines/" title="Previous Post: Audience modeling with Spark ML Pipelines">&laquo; Audience modeling with Spark ML Pipelines</a>
      
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

  <aside class="sidebar">
   
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:eugenezhulenev.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/09/16/spark-ml-for-big-and-small-data/">Optimizing Spark Machine Learning for Small Data</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/09/09/audience-modeling-with-spark-ml-pipelines/">Audience Modeling With Spark ML Pipelines</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/07/15/interactive-audience-analytics-with-spark-and-hyperloglog/">Interactive Audience Analytics With Spark and HyperLogLog</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/06/10/feature-engineering-at-scale/">Feature Engineering at Scale With Spark</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/11/20/twitter-analytics-with-spark/">Building Twitter Live Stream Analytics With Spark and Cassandra</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/ezhulenev">@ezhulenev</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'ezhulenev',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>



    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Eugene Zhulenev -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'eugenezhulenev';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://eugenezhulenev.com/blog/2015/09/16/spark-ml-for-big-and-small-data/';
        var disqus_url = 'http://eugenezhulenev.com/blog/2015/09/16/spark-ml-for-big-and-small-data/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>



<script>
  $(document).ready(function() {  
  var stickyNavTop = $('nav').offset().top;  
    
  var stickyNav = function(){  
  var scrollTop = $(window).scrollTop();  
         
  if (scrollTop > stickyNavTop) {   
      $('nav').addClass('sticky');  
  } else {  
      $('nav').removeClass('sticky');   
  }  
  };  
    
  stickyNav();  
    
  $(window).scroll(function() {  
      stickyNav();  
  });  
  });  
</script>


</body>
</html>
